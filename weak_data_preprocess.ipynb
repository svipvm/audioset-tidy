{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, os, librosa, soundfile, json, h5py, logging\n",
    "\n",
    "import librosa.display\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from utils.util_process import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/media/ubuntu/HD_new/download/audioset/audios'\n",
    "META_DIR = '/media/ubuntu/HD_new/download/audioset/metadata'\n",
    "SAVE_DIR = '/media/ubuntu/ssd2t/AIGroup/Audio-Data/audioset'\n",
    "\n",
    "PROCESS_MODE = 'unbalanced_train'\n",
    "AUDIO_DIR = glob.glob(f\"{DATA_DIR}/{PROCESS_MODE}_segments/unbalanced*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_metadata(csv_path, classes_num, id_to_ix):\n",
    "    \"\"\"Read metadata of AudioSet from a csv file.\n",
    "\n",
    "    Args:\n",
    "      csv_path: str\n",
    "\n",
    "    Returns:\n",
    "      meta_dict: {'audio_name': (audios_num,), 'target': (audios_num, classes_num)}\n",
    "    \"\"\"\n",
    "\n",
    "    with open(csv_path, 'r') as fr:\n",
    "        lines = fr.readlines()\n",
    "        lines = lines[3:]   # Remove heads\n",
    "\n",
    "    audios_num = len(lines)\n",
    "    targets = []\n",
    "    audio_names = []\n",
    " \n",
    "    for n, line in enumerate(lines):\n",
    "        items = line.split(', ')\n",
    "        \"\"\"items: ['--4gqARaEJE', '0.000', '10.000', '\"/m/068hy,/m/07q6cd_,/m/0bt9lr,/m/0jbk\"\\n']\"\"\"\n",
    "\n",
    "        audio_name = 'Y{}.wav'.format(items[0])   # Audios are started with an extra 'Y' when downloading\n",
    "        label_ids = items[3].split('\"')[1].split(',')\n",
    "\n",
    "        audio_names.append(audio_name)\n",
    "\n",
    "        # Target\n",
    "        # for id in label_ids:\n",
    "        #     ix = id_to_ix[id]\n",
    "        #     targets[n, ix] = 1\n",
    "        targets.append([id_to_ix[id_] for id_ in label_ids])\n",
    "        \n",
    "    meta_dict = {'audio_name': audio_names, 'target': targets}\n",
    "    return meta_dict\n",
    "\n",
    "def pad_or_truncate(x, audio_length):\n",
    "    \"\"\"Pad all audio to specific length.\"\"\"\n",
    "    if len(x) <= audio_length:\n",
    "        return np.concatenate((x, np.zeros(audio_length - len(x))), axis=0)\n",
    "    else:\n",
    "        return x[0 : audio_length]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "527\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>mid</th>\n",
       "      <th>display_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>/m/09x0r</td>\n",
       "      <td>Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>/m/05zppz</td>\n",
       "      <td>Male speech, man speaking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>/m/02zsn</td>\n",
       "      <td>Female speech, woman speaking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>/m/0ytgt</td>\n",
       "      <td>Child speech, kid speaking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>/m/01h8n0</td>\n",
       "      <td>Conversation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        mid                   display_name\n",
       "0      0   /m/09x0r                         Speech\n",
       "1      1  /m/05zppz      Male speech, man speaking\n",
       "2      2   /m/02zsn  Female speech, woman speaking\n",
       "3      3   /m/0ytgt     Child speech, kid speaking\n",
       "4      4  /m/01h8n0                   Conversation"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_labels_df = pd.read_csv(f'{META_DIR}/class_labels_indices.csv', delimiter=',')\n",
    "num_classes = class_labels_df.shape[0]\n",
    "\n",
    "labels = class_labels_df['display_name'].tolist()\n",
    "mid_list = class_labels_df['mid'].tolist()\n",
    "\n",
    "lb_to_ix = {label : i for i, label in enumerate(labels)}\n",
    "ix_to_lb = {i : label for i, label in enumerate(labels)}\n",
    "\n",
    "id_to_ix = {id : i for i, id in enumerate(mid_list)}\n",
    "ix_to_id = {i : id for i, id in enumerate(mid_list)}\n",
    "\n",
    "# sample_rate = 32000\n",
    "# clip_samples = sample_rate * 10     # Audio clips are 10-second\n",
    "\n",
    "params = {\n",
    "    'input_size': (1001, 64),\n",
    "    'sample_rate': 32000,\n",
    "    'clip_samples': 32000 * 10, \n",
    "    'n_fft': 1024,\n",
    "    'hop_length': 320,\n",
    "    'win_length': 1024,\n",
    "    'lower_hertz': 50,\n",
    "    'upper_hertz': 14000,\n",
    "    'mel_bins': 64\n",
    "}\n",
    "\n",
    "print(num_classes)\n",
    "class_labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2041789 dict_keys(['audio_name', 'target'])\n"
     ]
    }
   ],
   "source": [
    "all_meta_dict = read_metadata(f\"{META_DIR}/{PROCESS_MODE}_segments.csv\", num_classes, id_to_ix)\n",
    "audios_num = len(all_meta_dict['audio_name'])\n",
    "print(audios_num, all_meta_dict.keys())\n",
    "\n",
    "meta_id_label_mapper = {\n",
    "    all_meta_dict['audio_name'][i]: all_meta_dict['target'][i] for i in range(audios_num)\n",
    "}\n",
    "# print(list(meta_id_label_mapper.keys())[:3])\n",
    "# print(list(meta_id_label_mapper.values())[:3])\n",
    "\n",
    "with open(\"metadata/wav_id_labels.json\", 'w') as f:\n",
    "    f.write(json.dumps(meta_id_label_mapper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [01:48<00:00,  2.64s/it]\n"
     ]
    }
   ],
   "source": [
    "for audio_dir in tqdm(AUDIO_DIR):\n",
    "    hdf5_file = f\"{SAVE_DIR}/{PROCESS_MODE}/{os.path.basename(audio_dir)}.h5\"\n",
    "    os.makedirs(os.path.dirname(hdf5_file), exist_ok=True)\n",
    "    wav_files = glob.glob(f\"{audio_dir}/*\")[:100]\n",
    "    audios_num = len(wav_files)\n",
    "    \n",
    "    with h5py.File(hdf5_file, 'w') as hf:\n",
    "        hf.create_dataset('audio_name', shape=((audios_num,)), dtype='S20')\n",
    "        hf.create_dataset('logmel', shape=((audios_num, *params['input_size'])), dtype=np.float32)\n",
    "        hf.create_dataset('target', shape=((audios_num, )), dtype=\n",
    "                                h5py.special_dtype(vlen=np.dtype('int32')))\n",
    "        hf.attrs.create('sample_rate', data=params['sample_rate'], dtype=np.int32)\n",
    "\n",
    "        # Pack waveform & target of several audio clips to a single hdf5 file\n",
    "        for n, wav_file in enumerate(wav_files):\n",
    "            audio_path = os.path.join(audio_dir, wav_file)\n",
    "            # break\n",
    "            if os.path.isfile(audio_path):\n",
    "                # logging.info('{} {}'.format(n, audio_path))\n",
    "                (audio, _) = librosa.core.load(audio_path, sr=params['sample_rate'], mono=True)\n",
    "                audio = pad_or_truncate(audio, params['clip_samples'])\n",
    "                melspec = spectrogram(data=audio,\n",
    "                                n_fft=params['n_fft'], \n",
    "                                hop_length=params['hop_length'], \n",
    "                                win_length=params['win_length'],\n",
    "                                window='hann',\n",
    "                                center=True,\n",
    "                                pad_mode='reflect')\n",
    "                logmel = logmel_spectrogram(data=melspec,\n",
    "                                            sr=params['sample_rate'],\n",
    "                                            n_fft=params['n_fft'], \n",
    "                                            n_mels=params['mel_bins'],\n",
    "                                            fmin=params['lower_hertz'],\n",
    "                                            fmax=params['upper_hertz'])\n",
    "                audio_name = os.path.basename(wav_file)\n",
    "                hf['audio_name'][n] = audio_name\n",
    "                hf['logmel'][n] = logmel\n",
    "                hf['target'][n] = meta_id_label_mapper[audio_name]\n",
    "            else:\n",
    "                logging.info('{} File does not exist! {}'.format(n, audio_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_debug' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/whq/projects/with-dog-audio/audioset-tidy/weak_data_preprocess.ipynb 单元格 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2258706578742d475055227d/home/whq/projects/with-dog-audio/audioset-tidy/weak_data_preprocess.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m _debug\n",
      "\u001b[0;31mNameError\u001b[0m: name '_debug' is not defined"
     ]
    }
   ],
   "source": [
    "_debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for audio_dir in AUDIO_DIR:\n",
    "    print(audio_dir)\n",
    "    wav_files = glob.glob(f\"{audio_dir}/*\")\n",
    "    print(len(wav_files))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = '/media/ubuntu/HD_new/Data/audioset_tagging/hdf5s/waveforms/unbalanced_train/unbalanced_train_part35.h5'\n",
    "with h5py.File(output_file, \"r\") as h5_file:\n",
    "    print(\"H5文件中的数据集名称:\", list(h5_file.keys()))\n",
    "    print(h5_file[\"audio_name\"].shape)\n",
    "    print(h5_file[\"audio_name\"][:10])\n",
    "    print(h5_file[\"target\"].shape)\n",
    "    print(h5_file[\"waveform\"].shape)\n",
    "    print(h5_file[\"waveform\"][0])\n",
    "    # print(type(h5_file[\"labels\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H5文件中的数据集名称: ['audio_name', 'logmel', 'target']\n",
      "(46796,)\n",
      "(46796,)\n",
      "(46796, 1001, 64)\n",
      "b''\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "output_file = '/media/ubuntu/ssd2t/AIGroup/Audio-Data/audioset/unbalanced_train/unbalanced_train_segments_part24.h5'\n",
    "with h5py.File(output_file, \"r\") as h5_file:\n",
    "    print(\"H5文件中的数据集名称:\", list(h5_file.keys()))\n",
    "    print(h5_file[\"audio_name\"].shape)\n",
    "    # print(h5_file[\"audio_name\"][:10])\n",
    "    print(h5_file[\"target\"].shape)\n",
    "    print(h5_file[\"logmel\"].shape)\n",
    "    print(h5_file[\"audio_name\"][-2])\n",
    "    print(h5_file[\"logmel\"][-2])\n",
    "    print(h5_file[\"target\"][-2])\n",
    "    # print(type(h5_file[\"labels\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H5文件中的数据集名称: ['audio_name', 'hdf5_path', 'index_in_hdf5', 'target']\n"
     ]
    }
   ],
   "source": [
    "output_file = '/media/ubuntu/HD_new/Data/audioset_tagging/hdf5s/indexes/full_train.h5'\n",
    "with h5py.File(output_file, \"r\") as h5_file:\n",
    "    print(\"H5文件中的数据集名称:\", list(h5_file.keys()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_whq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
